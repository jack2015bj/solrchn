# morphline.conf example file
# Dead simple example of for parsing 'plaint text' files in this format:
# File-ID: <id>
# Plain text...


# Specify server locations in a SOLR_LOCATOR variable; used later in variable substitutions:
SOLR_LOCATOR : {
  # Name of solr collection
  collection : zh
  
  # ZooKeeper ensemble
  zkHost : "ip-172-31-34-100.us-west-2.compute.internal:2181/solr"
  
  # The maximum number of documents to send to Solr per network batch (throughput knob)
  # batchSize : 100
}

# Specify an array of one or more morphlines, each of which defines an ETL 
# transformation chain. A morphline consists of one or more (potentially 
# nested) commands. A morphline is a way to consume records (e.g. Flume events, 
# HDFS files or blocks), turn them into a stream of records, and pipe the stream 
# of records through a set of easily configurable transformations on it's way to 
# Solr.
morphlines : [
  {
    # Name used to identify a morphline. E.g. used if there are multiple morphlines in a 
    # morphline config file
    id : morphline1 
    
    # Import all morphline commands in these java packages and their subpackages.
    # Other commands that may be present on the classpath are not visible to this morphline.
    importCommands : ["org.kitesdk.**", "org.apache.solr.**"]
    
    commands : [
    {
        ## Read the text document stream and break it up into individual messages.
        ## The beginning of a message is marked by regex clause below
        ## The reason we use this command is that one event can have multiple
        ## messages
        readMultiLine {
            regex : "^File-Name: *<.*?>.*?\n"
            what : next
            charset : UTF-8
        }
    }
    ## Break up text into SOLR fields
    {
        if {
            conditions: [
            {
                not{
                    grok {
                        expressions : {
                           message: """(?s)(.*?)(^File-Name: <)(?<id>(.+?))(>.*?\n)(?<chn>(.*))"""
                        }
                        extract: inplace
                        findSubstrings: false
                        addEmptyStrings: false
                        numRequiredMatches: all
                    }
                }
            }
            ]
            then:[
            { logInfo { format : "found no grok match: {}", args : ["@{}"] } }
            { dropRecord {} }
            ]
        }
    }

    # add Unique ID, in case our message_id field from above is not present
    {
        generateUUID {
            field:id
        }
    }

    # Consume the output record of the previous command and pipe another
    # record downstream.
    #
    # This command sanitizes record fields that are unknown to Solr schema.xml
    # by deleting them. Recall that Solr throws an exception on any attempt to
    # load a document that contains a field that isn't specified in schema.xml
    {
        sanitizeUnknownSolrFields {
            # Location from which to fetch Solr schema
            solrLocator : ${SOLR_LOCATOR}
        }
    }

    # load the record into a SolrServer or MapReduce SolrOutputFormat.
    {
        loadSolr {
            solrLocator : ${SOLR_LOCATOR}
        }
    }
    ]
  }
]
